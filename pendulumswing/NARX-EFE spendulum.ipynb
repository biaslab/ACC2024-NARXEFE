{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff958e43",
   "metadata": {},
   "source": [
    "# Bayesian black-box model-predictive control\n",
    "\n",
    "An Expected Free Energy minimizing agent based on a nonlinear autoregressive model with exogenous input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9a73c",
   "metadata": {},
   "source": [
    "## System: driven damped pendulum\n",
    "\n",
    "Consider a single pendulum with angle $\\theta(t)$ and input $u(t)$ evolving according to:\n",
    "\n",
    "$$ \\ddot{\\theta} + \\frac{\\mathcal{g}}{l} \\sin(\\theta) + \\frac{\\gamma}{l} \\dot{\\theta} = \\frac{1}{ml} u\\, .$$\n",
    "\n",
    "where $m$ is mass, $l$ is length, $\\gamma$ is damping and $\\mathcal{g}$ is Earth's gravity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using Optim\n",
    "using RxInfer\n",
    "using JLD\n",
    "using SpecialFunctions\n",
    "using LinearAlgebra\n",
    "using LaTeXStrings\n",
    "using Distances\n",
    "using ProgressMeter\n",
    "using Distributions\n",
    "using Plots; default(grid=false, label=\"\", linewidth=3,margin=20Plots.pt)\n",
    "using Random; Random.seed!(123)\n",
    "\n",
    "includet(\"../NARXAgents.jl\"); using .NARXAgents\n",
    "includet(\"../Pendulums.jl\"); using .Pendulums\n",
    "includet(\"../location_scale_tdist.jl\"); using .location_scale_tdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5397ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System parameters\n",
    "sys_mass = 1.0\n",
    "sys_length = 0.5\n",
    "sys_damping = 0.0025\n",
    "sys_mnoise_sd = 1e-3\n",
    "sys_ulims = (-10., 10.)\n",
    "Δt = 0.1\n",
    "\n",
    "init_state = [0.0, 0.0]\n",
    "pendulum = SPendulum(init_state = init_state, \n",
    "                     mass = sys_mass, \n",
    "                     length = sys_length, \n",
    "                     damping = sys_damping, \n",
    "                     mnoise_sd = sys_mnoise_sd, \n",
    "                     torque_lims = sys_ulims,\n",
    "                     Δt=Δt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "tsteps = range(0.0, step=Δt, length=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01918e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "A  = rand(10)*300 .- 100\n",
    "Ω  = rand(10)*3\n",
    "controls = mean([A[i]*sin.(Ω[i].*tsteps) for i = 1:10]) ./ 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = zeros(2,N)\n",
    "observations = zeros(N)\n",
    "torques = zeros(N)\n",
    "\n",
    "for k in 1:N\n",
    "    states[:,k] = pendulum.state\n",
    "    observations[k] = pendulum.sensor\n",
    "    step!(pendulum, controls[k])\n",
    "    torques[k] = pendulum.torque\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddde7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = plot(ylabel=\"angle\")\n",
    "plot!(tsteps, states[1,:], color=\"blue\", label=\"state\")\n",
    "scatter!(tsteps, observations, color=\"black\", label=\"measurements\")\n",
    "p2 = plot(xlabel=\"time [s]\", ylabel=\"torque\")\n",
    "plot!(tsteps, controls[:], color=\"red\")\n",
    "plot!(tsteps, torques[:], color=\"purple\")\n",
    "plot(p1,p2, layout=grid(2,1, heights=[0.7, 0.3]), size=(900,600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096a613",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment specification \n",
    "N = 100\n",
    "tsteps = range(0.0, step=Δt, length=N)\n",
    "T = 5\n",
    "\n",
    "# NARX basis settings\n",
    "H = 2\n",
    "Ly = 2\n",
    "Lu = 2\n",
    "M = size(pol(zeros(Ly+Lu+1), degree=H),1);\n",
    "\n",
    "# System specification\n",
    "init_state = [0.0, 0.0];\n",
    "\n",
    "# Agent specification\n",
    "α0 = 1e2 # Must be larger than 1.0 \n",
    "β0 = 1e-1\n",
    "μ0 = 1e-8ones(M)\n",
    "Λ0 = 1/2*diagm(ones(M));\n",
    "η = 1e-3;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a78c55",
   "metadata": {},
   "source": [
    "### Expected Free Energy minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pendulum = SPendulum(init_state = init_state, \n",
    "                     mass = sys_mass, \n",
    "                     length = sys_length, \n",
    "                     damping = sys_damping, \n",
    "                     mnoise_sd = sys_mnoise_sd, \n",
    "                     torque_lims = sys_ulims,\n",
    "                     Δt=Δt)\n",
    "\n",
    "# Set goal priors for time horizon\n",
    "goals = [Normal(3.141592, 0.5) for t in 1:T]\n",
    "\n",
    "# Start agent\n",
    "agent = NARXAgent(μ0, Λ0, α0, β0,\n",
    "                  goal_prior=goals, \n",
    "                  delay_inp=Lu, \n",
    "                  delay_out=Ly, \n",
    "                  pol_degree=H,\n",
    "                  time_horizon=T)   \n",
    "                  \n",
    "yb = zeros(Ly)\n",
    "ub = zeros(Lu+1)\n",
    "\n",
    "uu = range(sys_ulims[1], stop=sys_ulims[2], length=300)\n",
    "J_MI = [mutualinfo(agent, yb, ub, u_) for u_ in uu]\n",
    "J_CE = [crossentropy(agent, yb, ub, goals[1], u_) for u_ in uu]\n",
    "J = J_CE - J_MI\n",
    "\n",
    "p11 = plot(uu, J_CE)\n",
    "p12 = plot(uu, J_MI)\n",
    "p13 = plot(uu, J, ylims=(minimum(J), minimum(J)+3))\n",
    "plot(p11, p12, p13, layout=(1,3), size=(900,300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03330f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start system\n",
    "pendulum = SPendulum(init_state = init_state, \n",
    "                     mass = sys_mass, \n",
    "                     length = sys_length, \n",
    "                     damping = sys_damping, \n",
    "                     mnoise_sd = sys_mnoise_sd, \n",
    "                     torque_lims = sys_ulims,\n",
    "                     Δt=Δt)\n",
    "\n",
    "# Set goal priors for time horizon\n",
    "goals = [Normal(3.141592, 0.5) for t in 1:T]\n",
    "\n",
    "# Start agent\n",
    "agent = NARXAgent(μ0, Λ0, α0, β0,\n",
    "                  goal_prior=goals, \n",
    "                  delay_inp=Lu, \n",
    "                  delay_out=Ly, \n",
    "                  pol_degree=H,\n",
    "                  time_horizon=T,\n",
    "                  control_prior_precision=η)\n",
    "\n",
    "# Preallocate\n",
    "y_EFE = zeros(N)\n",
    "z_EFE = zeros(2,N)\n",
    "u_EFE = zeros(N+T)\n",
    "μ_EFE = [μ0]\n",
    "Λ_EFE = [Λ0]\n",
    "α_EFE = [α0]\n",
    "β_EFE = [β0]\n",
    "F_EFE = zeros(N)\n",
    "pred_m = zeros(N,T)\n",
    "pred_v = zeros(N,T)\n",
    "MI_EFE = zeros(N,T)\n",
    "CE_EFE = zeros(N,T)\n",
    "Nu = 200\n",
    "J_MI = zeros(N,Nu)\n",
    "J_CE = zeros(N,Nu)\n",
    "JEFE = zeros(N,Nu)\n",
    "urange = range(sys_ulims[1], stop=sys_ulims[2], length=Nu)\n",
    "\n",
    "for k in 1:N    \n",
    "    \n",
    "    # Update parameter beliefs\n",
    "    y_EFE[k] = pendulum.sensor\n",
    "    NARXAgents.update!(agent, y_EFE[k], u_EFE[k])\n",
    "    F_EFE[k] = agent.free_energy\n",
    "    push!( μ_EFE, agent.μ )\n",
    "    push!( Λ_EFE, agent.Λ )\n",
    "    push!( α_EFE, agent.α )\n",
    "    push!( β_EFE, agent.β )\n",
    "    \n",
    "    # Optimal control\n",
    "    policy = minimizeEFE(agent, goals, u_0=zeros(T), time_limit=30., control_lims=sys_ulims)\n",
    "    u_EFE[k+1:k+T] = policy\n",
    "\n",
    "    MI_EFE[k,:] = [mutualinfo(agent, agent.ybuffer, agent.ubuffer, u_t) for u_t in policy]\n",
    "    CE_EFE[k,:] = [crossentropy(agent, agent.ybuffer, agent.ubuffer, goals[1], u_t) for u_t in policy]\n",
    "\n",
    "    J_MI[k,:] = [mutualinfo(agent, agent.ybuffer, agent.ubuffer, u_i) for u_i in urange]\n",
    "    J_CE[k,:] = [crossentropy(agent, agent.ybuffer, agent.ubuffer, goals[1], u_i) for u_i in urange]\n",
    "    JEFE[k,:] = J_CE[k,:] .- J_MI[k,:]\n",
    "    \n",
    "    # Store future predictions\n",
    "    pred_m[k,:], pred_v[k,:] = predictions(agent, policy, time_horizon=T)\n",
    "\n",
    "    # Act upon environment\n",
    "    step!(pendulum, u_EFE[k+1])\n",
    "    z_EFE[:,k] = pendulum.state\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77034e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = plot(tsteps[2:end], y_EFE[2:end], color=\"black\", label=\"observations\")\n",
    "hline!([mean(goals[1])], color=\"green\", label=\"goal\")\n",
    "p4 = plot(tsteps[2:end], u_EFE[2:end-T], color=\"red\", ylabel=\"controls\", xlabel=\"time [s]\")\n",
    "\n",
    "plot(p1,p4, layout=grid(2,1, heights=[.7, .3]), size=(900,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"figures/NARX-EFE-1Pendulum-trial.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"results/EFE.jld\", \"y_EFE\", y_EFE, \"z_EFE\", z_EFE, \"u_EFE\", u_EFE, \"MI_EFE\", MI_EFE, \"CE_EFE\", CE_EFE,\n",
    "    \"pred_m\", pred_m, \"pred_v\", pred_v, \"goals_m\", mean.(goals), \"goals_v\", var.(goals),\n",
    "    \"sys_ulims\", sys_ulims, \"tsteps\", tsteps, \"T\", T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "limsb = [minimum(y_EFE)*1.5, maximum(y_EFE)*1.5]\n",
    "\n",
    "window = 20\n",
    "\n",
    "anim = @animate for k in 2:2:(N-T-1)\n",
    "    \n",
    "    if k <= window\n",
    "        plot(tsteps[1:k], y_EFE[1:k], color=\"blue\", xlims=(tsteps[1], tsteps[window+T+1]+0.5), label=\"past data\", xlabel=\"time (sec)\", ylims=limsb, size=(900,300))\n",
    "        plot!(tsteps[k:k+T], y_EFE[k:k+T], color=\"purple\", label=\"true future\", linestyle=:dot)\n",
    "        plot!(tsteps[k+1:k+T], pred_m[k,:], ribbon=pred_v[k,:], label=\"predicted future\", color=\"orange\", legend=:topleft)\n",
    "        plot!(mean.(goals), color=\"green\")\n",
    "    else\n",
    "        plot(tsteps[k-window:k], y_EFE[k-window:k], color=\"blue\", xlims=(tsteps[k-window], tsteps[k+T+1]+0.5), label=\"past data\", xlabel=\"time (sec)\", ylims=limsb, size=(900,300))\n",
    "        plot!(tsteps[k:k+T], y_EFE[k:k+T], color=\"purple\", label=\"true future\", linestyle=:dot)\n",
    "        plot!(tsteps[k+1:k+T], pred_m[k,:], ribbon=pred_v[k,:], label=\"prediction\", color=\"orange\", legend=:topleft)\n",
    "        plot!(mean.(goals), color=\"green\")\n",
    "    end\n",
    "    \n",
    "end\n",
    "gif(anim, \"figures/NARX-EFE-1Pendulum-planning.gif\", fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84357f8",
   "metadata": {},
   "source": [
    "### Quadratic cost with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start system\n",
    "pendulum = SPendulum(init_state = init_state, \n",
    "                     mass = sys_mass, \n",
    "                     length = sys_length, \n",
    "                     damping = sys_damping, \n",
    "                     mnoise_sd = sys_mnoise_sd, \n",
    "                     torque_lims = sys_ulims,\n",
    "                     Δt=Δt)\n",
    "\n",
    "# Start agent\n",
    "agent = NARXAgent(μ0, Λ0, α0, β0,\n",
    "                  goal_prior=goals, \n",
    "                  delay_inp=Lu, \n",
    "                  delay_out=Ly, \n",
    "                  pol_degree=H,\n",
    "                  time_horizon=T,\n",
    "                  control_prior_precision=η)\n",
    "\n",
    "# Preallocate\n",
    "y_QCR = zeros(N)\n",
    "z_QCR = zeros(2,N)\n",
    "u_QCR = zeros(N+T)\n",
    "μ_QCR = [μ0]\n",
    "Λ_QCR = [Λ0]\n",
    "α_QCR = [α0]\n",
    "β_QCR = [β0]\n",
    "F_QCR = zeros(N)\n",
    "pred_m = zeros(N,T)\n",
    "pred_v = zeros(N,T)\n",
    "MI_QCR = zeros(N,T)\n",
    "CE_QCR = zeros(N,T)\n",
    "J_QCR = zeros(N,T)\n",
    "Nu = 200\n",
    "J_QCR = zeros(N,Nu)\n",
    "urange = range(sys_ulims[1], stop=sys_ulims[2], length=Nu)\n",
    "\n",
    "@showprogress for k in 1:N    \n",
    "    \n",
    "    # Update parameter beliefs\n",
    "    y_QCR[k] = pendulum.sensor\n",
    "    NARXAgents.update!(agent, y_QCR[k], u_QCR[k])\n",
    "    F_QCR[k] = agent.free_energy\n",
    "    push!( μ_QCR, agent.μ )\n",
    "    push!( Λ_QCR, agent.Λ )\n",
    "    push!( α_QCR, agent.α )\n",
    "    push!( β_QCR, agent.β )\n",
    "    \n",
    "    # Optimal control\n",
    "    policy = minimizeQCR(agent, goals, u_0=zeros(T), time_limit=30.,control_lims=sys_ulims)\n",
    "    u_QCR[k+1:k+T] = policy\n",
    "\n",
    "    MI_QCR[k,:] = [mutualinfo(agent, agent.ybuffer, agent.ubuffer, u_t) for u_t in policy]\n",
    "    CE_QCR[k,:] = [crossentropy(agent, agent.ybuffer, agent.ubuffer, goals[1], u_t) for u_t in policy]\n",
    "\n",
    "    J_QCR[k,:] = [QCR(agent, agent.ybuffer, agent.ubuffer, goals[1], u_t)+η*u_t^2 for u_t in urange]\n",
    "    \n",
    "    # Store future predictions\n",
    "    pred_m[k,:], pred_v[k,:] = predictions(agent, policy, time_horizon=T)\n",
    "\n",
    "    # Act upon environment\n",
    "    step!(pendulum, u_QCR[k+1])\n",
    "    z_QCR[:,k] = pendulum.state\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e6c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = plot(tsteps[2:end], y_QCR[2:end], color=\"black\", label=\"observations\")\n",
    "hline!([mean(goals[1])], color=\"green\", label=\"goal\")\n",
    "p4 = plot(tsteps[2:end], u_QCR[2:end-T], color=\"red\", ylabel=\"controls\", xlabel=\"time [s]\")\n",
    "\n",
    "plot(p1,p4, layout=grid(2,1, heights=[.7, .3]), size=(900,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"figures/NARX-QCR-1Pendulum-trial.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"results/QCR.jld\", \"y_QCR\", y_QCR, \"z_QCR\", z_QCR, \"u_QCR\", u_QCR, \"MI_QCR\", MI_QCR, \"CE_QCR\", CE_QCR,\n",
    "    \"pred_m\", pred_m, \"pred_v\", pred_v, \"goals_m\", mean.(goals), \"goals_v\", var.(goals),\n",
    "    \"sys_ulims\", sys_ulims, \"tsteps\", tsteps, \"T\", T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "limsb = [minimum(y_QCR)*1.5, maximum(y_QCR)*1.5]\n",
    "\n",
    "window = 20\n",
    "\n",
    "anim = @animate for k in 2:2:(N-T-1)\n",
    "    \n",
    "    if k <= window\n",
    "        plot(tsteps[1:k], y_QCR[1:k], color=\"blue\", xlims=(tsteps[1], tsteps[window+T+1]+0.5), label=\"past data\", xlabel=\"time (sec)\", ylims=limsb, size=(900,300))\n",
    "        plot!(tsteps[k:k+T], y_QCR[k:k+T], color=\"purple\", label=\"true future\", linestyle=:dot)\n",
    "        plot!(tsteps[k+1:k+T], pred_m[k,:], ribbon=pred_v[k,:], label=\"predicted future\", color=\"orange\", legend=:topleft)\n",
    "        hline!([mean(goals[1])], color=\"green\")\n",
    "    else\n",
    "        plot(tsteps[k-window:k], y_QCR[k-window:k], color=\"blue\", xlims=(tsteps[k-window], tsteps[k+T+1]+0.5), label=\"past data\", xlabel=\"time (sec)\", ylims=limsb, size=(900,300))\n",
    "        plot!(tsteps[k:k+T], y_QCR[k:k+T], color=\"purple\", label=\"true future\", linestyle=:dot)\n",
    "        plot!(tsteps[k+1:k+T], pred_m[k,:], ribbon=pred_v[k,:], label=\"prediction\", color=\"orange\", legend=:topleft)\n",
    "        hline!([mean(goals[1])], color=\"green\")\n",
    "    end\n",
    "    \n",
    "end\n",
    "gif(anim, \"figures/NARX-QCR-1Pendulum-planning.gif\", fps=24)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
